{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ResNet_cifar10 import BasicBlock, Bottleneck, MyResNet\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU\n",
    "def Device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "def Load_Data():\n",
    "    NUM_TRAIN = 49000\n",
    "\n",
    "    transform_train = T.Compose([\n",
    "                    T.RandomCrop(size=32,padding=4),\n",
    "                    T.RandomHorizontalFlip(),\n",
    "                    T.ToTensor(),\n",
    "                    T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "                ])\n",
    "\n",
    "    transform = T.Compose([\n",
    "                    T.ToTensor(),\n",
    "                    T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "                ])\n",
    "\n",
    "    cifar10_train = dset.CIFAR10('./datasets', train=True, download=True, transform=transform_train)\n",
    "    loader_train = DataLoader(cifar10_train, batch_size=64, sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
    "\n",
    "    cifar10_val = dset.CIFAR10('./datasets', train=True, download=True, transform=transform)\n",
    "    loader_val = DataLoader(cifar10_val, batch_size=64, sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, 50000)))\n",
    "\n",
    "    cifar10_test = dset.CIFAR10('./datasets', train=False, download=True, transform=transform)\n",
    "    loader_test = DataLoader(cifar10_test, batch_size=64)\n",
    "\n",
    "    return loader_train, loader_val, loader_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_history = []\n",
    "accuracy_train_history = []\n",
    "accuracy_val_history = []\n",
    "device = Device()\n",
    "loader_train, loader_val, loader_test = Load_Data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "def Check_Accuracy(loader, model):\n",
    "    if loader.dataset.train:\n",
    "        print(\"Accuracy on Validation Set: \")\n",
    "    else:\n",
    "        print(\"Accuracy on Test Set: \")\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for x,y in loader:\n",
    "            x = x.to(device, dtype = torch.float32)\n",
    "            y = y.to(device, dtype = torch.long)\n",
    "\n",
    "            scores = model(x)\n",
    "            _, predict = torch.max(scores, 1)\n",
    "            correct += (predict == y).sum()\n",
    "            total += predict.size(0)\n",
    "        accuracy = correct / total\n",
    "        accuracy_val_history.append(accuracy)\n",
    "        print('{:.2%}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "def Train(model, optimizer, epochs = 1):\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    model = model.to(device = device)\n",
    "    model.train() # setup for BN\n",
    "    for e in range(epochs):\n",
    "        print('Epoch(%d)' % e)\n",
    "        for t,(x,y) in enumerate(loader_train):\n",
    "            x = x.to(device, dtype = torch.float32)\n",
    "            y = y.to(device, dtype = torch.long)\n",
    "\n",
    "            scores = model(x)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(scores, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            _, predict = torch.max(scores, 1)\n",
    "            correct += (predict == y).sum()\n",
    "            total += predict.size(0)\n",
    "            accuracy_train_history.append(correct/total)\n",
    "\n",
    "            if t % 100 == 0:\n",
    "                print('Loss: %.4f' % loss)\n",
    "                loss_history.append(loss)\n",
    "                Check_Accuracy(loader_val, model)\n",
    "                print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Draw():\n",
    "    plt.xlabel('n')\n",
    "    plt.ylabel('loss')\n",
    "    n = np.arange(1, len(loss_history) + 1)\n",
    "    m = np.arange(1, len(accuracy_val_history) + 1)\n",
    "    k = np.arange(1, len(accuracy_train_history) + 1) / 100\n",
    "    plt.plot(n, loss_history, color = 'g')\n",
    "    plt.plot(m, accuracy_val_history, color = 'r')\n",
    "    plt.plot(k, accuracy_train_history, color = 'b')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-1\n",
    "model = MyResNet(BasicBlock, [2,2,2,2], 10)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, \n",
    "                    momentum=0.9, weight_decay=1e-4)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "Train(model, optimizer, epochs = 5)\n",
    "Draw()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
